{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.7)\n",
    "# llm = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000024FE0DF6E90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024FE0E91F60>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema.language_model import BaseLanguageModel\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# class OpenAIWrapper(BaseLanguageModel):\n",
    "#     def __init__(self):\n",
    "#         self.llm = genai()\n",
    "\n",
    "#     def generate(self, prompts, **kwargs):\n",
    "#         # Implement the generate method using self.llm\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = OpenAIWrapper()\n",
    "\n",
    "quiz_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['RESPONSE_JSON', 'number', 'subject', 'text', 'tone'], template='\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make {number} MCQs\\n### RESPONSE_JSON\\n{RESPONSE_JSON}\\n\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000024FE0DF6E90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024FE0E91F60>, openai_api_key='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', openai_proxy=''), output_key='quiz')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm,prompt=quiz_evaluation_prompt,output_key=\"review\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"RESPONSE_JSON\"],output_variables=[\"quiz\", \"review\"], verbose=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"D:/Professional/Project/FinalYr/Eduverse_backend_FASTapi/documents/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH,\"r\") as file:\n",
    "    TEXT=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent progress in generative models have resulted in models that can produce realistic text, images and video that can potentially revolutionize the way humans work, create content and interact with machines. The workshop on Generative AI at AIMLSystems will focus on the entire life-cycle of building and deploying such Generative AI systems, including data collection and processing, developing systems and requisite infrastructure, applications it enables, and the ethics associated with such technology covering concerns related to fairness, transparency and accountability. We invite original, unpublished work on Artificial Intelligence with a focus on generative AI and their use cases. Specifically, the topics of interest include but are not limited to:\n",
      "\n",
      "Systems, architecture and infrastructure for Generative AI\n",
      "Machine learning and Modeling using LLMs and Diffusion models\n",
      "Large Language Models and its applications\n",
      "Multi-modal Generative AI and its applications\n",
      "Gen AI based Plugins and agents\n",
      "Deployment of Generative AI solutions\n",
      "Evaluation of Language and Diffusion based models\n",
      "Responsible use of Gen AI\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialChain(verbose=True, chains=[LLMChain(prompt=PromptTemplate(input_variables=['RESPONSE_JSON', 'number', 'subject', 'text', 'tone'], template='\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make {number} MCQs\\n### RESPONSE_JSON\\n{RESPONSE_JSON}\\n\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000024FE0DF6E90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024FE0E91F60>, openai_api_key='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', openai_proxy=''), output_key='quiz'), LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['quiz', 'subject'], template='\\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \\nif the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\\nQuiz_MCQs:\\n{quiz}\\n\\nCheck from an expert English Writer of the above quiz:\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000024FE0DF6E90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000024FE0E91F60>, openai_api_key='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', openai_proxy=''), output_key='review')], input_variables=['text', 'number', 'subject', 'tone', 'RESPONSE_JSON'], output_variables=['quiz', 'review'])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_evaluate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {'1': {'no': '1',\n",
    "  'mcq': 'multiple choice questions',\n",
    "  'options': {'a': 'choice here',\n",
    "   'b': 'choice here',\n",
    "   'c': 'choice here',\n",
    "   'd': 'choice here'},\n",
    "  'correct': 'correct answer'},\n",
    " '2': {'no': '2',\n",
    "  'mcq': 'multiple choice questions',\n",
    "  'options': {'a': 'choice here',\n",
    "   'b': 'choice here',\n",
    "   'c': 'choice here',\n",
    "   'd': 'choice here'},\n",
    "  'correct': 'correct answer'},\n",
    " '3': {'no': '3',\n",
    "  'mcq': 'multiple choice questions',\n",
    "  'options': {'a': 'choice here',\n",
    "   'b': 'choice here',\n",
    "   'c': 'choice here',\n",
    "   'd': 'choice here'},\n",
    "  'correct': 'correct answer'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT\n",
    "NUMBER=5\n",
    "SUBJECT=\"AI\"\n",
    "TONE=\"Simple\",\n",
    "RESPONSE_JSON=RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for AI students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "{\"1\": {\"no\": \"1\", \"mcq\": \"What is the focus of the workshop on Generative AI at AIMLSystems?\", \"options\": {\"a\": \"Developing machine learning models\", \"b\": \"Creating realistic text, images, and video\", \"c\": \"Exploring the ethics of Generative AI\", \"d\": \"Collecting and processing data\"}, \"correct\": \"The entire life-cycle of building and deploying Generative AI systems\"}, \n",
      "\"2\": {\"no\": \"2\", \"mcq\": \"Which of the following is NOT a topic of interest for the workshop?\", \"options\": {\"a\": \"Gen AI based Plugins and agents\", \"b\": \"Multi-modal Generative AI and its applications\", \"c\": \"Evaluation of Language and Diffusion based models\", \"d\": \"Artificial Intelligence in robotics\"}, \"correct\": \"Artificial Intelligence in robotics\"}, \n",
      "\"3\": {\"no\": \"3\", \"mcq\": \"What does LLMs stand for in the context of Generative AI?\", \"options\": {\"a\": \"Large Language Models\", \"b\": \"Low-level Modeling Methods\", \"c\": \"Long-term Learning Models\", \"d\": \"Linear Language Models\"}, \"correct\": \"Large Language Models\"}, \n",
      "\"4\": {\"no\": \"4\", \"mcq\": \"What aspect of Generative AI does the workshop emphasize on regarding ethics?\", \"options\": {\"a\": \"Accountability\", \"b\": \"Fairness and transparency\", \"c\": \"Data collection and processing\", \"d\": \"Developing systems and infrastructure\"}, \"correct\": \"Fairness and transparency\"}, \n",
      "\"5\": {\"no\": \"5\", \"mcq\": \"What is the main application of Diffusion models in Generative AI?\", \"options\": {\"a\": \"Generating realistic images\", \"b\": \"Building large-scale language models\", \"c\": \"Developing multi-modal AI systems\", \"d\": \"Deploying Generative AI solutions\"}, \"correct\": \"Generating realistic images\"}}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with  get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "\n",
    "        \"text\": TEXT,\n",
    "        \"number\": NUMBER,\n",
    "        \"subject\": SUBJECT,\n",
    "        \"tone\": TONE,\n",
    "        \"RESPONSE_JSON\": json.dumps(RESPONSE_JSON)\n",
    "\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get(\"quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"no\": \"1\", \"mcq\": \"What is the focus of the workshop on Generative AI at AIMLSystems?\", \"options\": {\"a\": \"Developing machine learning models\", \"b\": \"Creating realistic text, images, and video\", \"c\": \"Exploring the ethics of Generative AI\", \"d\": \"Collecting and processing data\"}, \"correct\": \"The entire life-cycle of building and deploying Generative AI systems\"}, \\n\"2\": {\"no\": \"2\", \"mcq\": \"Which of the following is NOT a topic of interest for the workshop?\", \"options\": {\"a\": \"Gen AI based Plugins and agents\", \"b\": \"Multi-modal Generative AI and its applications\", \"c\": \"Evaluation of Language and Diffusion based models\", \"d\": \"Artificial Intelligence in robotics\"}, \"correct\": \"Artificial Intelligence in robotics\"}, \\n\"3\": {\"no\": \"3\", \"mcq\": \"What does LLMs stand for in the context of Generative AI?\", \"options\": {\"a\": \"Large Language Models\", \"b\": \"Low-level Modeling Methods\", \"c\": \"Long-term Learning Models\", \"d\": \"Linear Language Models\"}, \"correct\": \"Large Language Models\"}, \\n\"4\": {\"no\": \"4\", \"mcq\": \"What aspect of Generative AI does the workshop emphasize on regarding ethics?\", \"options\": {\"a\": \"Accountability\", \"b\": \"Fairness and transparency\", \"c\": \"Data collection and processing\", \"d\": \"Developing systems and infrastructure\"}, \"correct\": \"Fairness and transparency\"}, \\n\"5\": {\"no\": \"5\", \"mcq\": \"What is the main application of Diffusion models in Generative AI?\", \"options\": {\"a\": \"Generating realistic images\", \"b\": \"Building large-scale language models\", \"c\": \"Developing multi-modal AI systems\", \"d\": \"Deploying Generative AI solutions\"}, \"correct\": \"Generating realistic images\"}}'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'no': '1',\n",
       "  'mcq': 'What is the focus of the workshop on Generative AI at AIMLSystems?',\n",
       "  'options': {'a': 'Developing machine learning models',\n",
       "   'b': 'Creating realistic text, images, and video',\n",
       "   'c': 'Exploring the ethics of Generative AI',\n",
       "   'd': 'Collecting and processing data'},\n",
       "  'correct': 'The entire life-cycle of building and deploying Generative AI systems'},\n",
       " '2': {'no': '2',\n",
       "  'mcq': 'Which of the following is NOT a topic of interest for the workshop?',\n",
       "  'options': {'a': 'Gen AI based Plugins and agents',\n",
       "   'b': 'Multi-modal Generative AI and its applications',\n",
       "   'c': 'Evaluation of Language and Diffusion based models',\n",
       "   'd': 'Artificial Intelligence in robotics'},\n",
       "  'correct': 'Artificial Intelligence in robotics'},\n",
       " '3': {'no': '3',\n",
       "  'mcq': 'What does LLMs stand for in the context of Generative AI?',\n",
       "  'options': {'a': 'Large Language Models',\n",
       "   'b': 'Low-level Modeling Methods',\n",
       "   'c': 'Long-term Learning Models',\n",
       "   'd': 'Linear Language Models'},\n",
       "  'correct': 'Large Language Models'},\n",
       " '4': {'no': '4',\n",
       "  'mcq': 'What aspect of Generative AI does the workshop emphasize on regarding ethics?',\n",
       "  'options': {'a': 'Accountability',\n",
       "   'b': 'Fairness and transparency',\n",
       "   'c': 'Data collection and processing',\n",
       "   'd': 'Developing systems and infrastructure'},\n",
       "  'correct': 'Fairness and transparency'},\n",
       " '5': {'no': '5',\n",
       "  'mcq': 'What is the main application of Diffusion models in Generative AI?',\n",
       "  'options': {'a': 'Generating realistic images',\n",
       "   'b': 'Building large-scale language models',\n",
       "   'c': 'Developing multi-modal AI systems',\n",
       "   'd': 'Deploying Generative AI solutions'},\n",
       "  'correct': 'Generating realistic images'}}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myFastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
